{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Jupyter Notebook to generate a CellML file for the selected structures in the Generic Cell Flatmap\n",
    "\n",
    "### The description for each cell of the Jupyter Notebook is provided in order as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "from sympy import *\n",
    "from sympy.utilities.mathml import c2p\n",
    "\n",
    "# b) Data extraction\n",
    "from pyomexmeta import RDF, eUriType\n",
    "import os\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import rdflib\n",
    "import re\n",
    "from lxml import etree\n",
    "\n",
    "# c) General\n",
    "import copy\n",
    "import difflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator as op\n",
    "import ast\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "import xlsxwriter\n",
    "\n",
    "# d) Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import markers\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.colors\n",
    "from pylab import rcParams\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use the code, you need to download and save the required ontologies as .csv files.\n",
    "\n",
    "- OPB: https://bioportal.bioontology.org/ontologies/OPB\n",
    "\n",
    "- GO: https://bioportal.bioontology.org/ontologies/GO\n",
    "\n",
    "- FMA: https://bioportal.bioontology.org/ontologies/FMA\n",
    "\n",
    "- CHEBI: https://bioportal.bioontology.org/ontologies/CHEBI\n",
    "\n",
    "Since the size of the stored ontologies exceeds the GitHub upload limit, the ontologies' .csv files are not uploaded here. Change the address which points to the ontologies on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nsha457\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3325: DtypeWarning: Columns (41,71,75,77,99,100,103,113,114,138,140,156,157,158,178,198) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\users\\nsha457\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3325: DtypeWarning: Columns (31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\users\\nsha457\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3325: DtypeWarning: Columns (11,12,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Ontologies:\n",
    "# Save the .csv files of each ontology from https://bioportal.bioontology.org/ontologies\n",
    "FMA = pd.read_csv('/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction/ontologies/FMA.csv')\n",
    "CHEBI = pd.read_csv('/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction/ontologies/CHEBI.csv')\n",
    "OPB = pd.read_csv('/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction/ontologies/OPB.csv')\n",
    "GO = pd.read_csv('/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction/ontologies/GO.csv')\n",
    "\n",
    "# Extraction of IDs & Labels in the ontologies\n",
    "fmaID = FMA['Class ID']\n",
    "fmaLabel= FMA['Preferred Label']\n",
    "chebiID = CHEBI['Class ID']\n",
    "chebiLabel= CHEBI['Preferred Label']\n",
    "opbID = OPB['Class ID']\n",
    "opbLabel= OPB['Preferred Label']\n",
    "goID = GO['Class ID']\n",
    "goLabel= GO['Preferred Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining thetemplate groups\n",
    "Here, a dictionary (**templateGroups**) has been generated to define which group of transporters/structures belong to which template. Template names are the keys **M1, M2, ...** and the dictionary values represent the name of the structures belonging each template. For each transporters/structure we need to have a CellML file in which their specific parameters are initialized and annotated. These files don't need to include any mathematical equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see which group of transporters/channels belong to\n",
    "# which template\n",
    "templateGroups = {'M1':['SLC1','SLC3','SLC5'],\n",
    "                  'M2':['SLC2','SLC4','SLC6']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the appropriate templates\n",
    "Here, we assume that the structures **SLC1 & SLC2** are selected from the flatmap. The goal is to generate a bond graph model of the composed structure (**SLC1+SLC2**) and provide a **CellML** file along with a **JSON** file. In this cell we find the required templates to use for the structure names. The dictionary **'inUse'** maps between the selected structures and their templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inUse ==> {'SLC1': ['M1'], 'SLC2': ['M2']}\n"
     ]
    }
   ],
   "source": [
    "# Let's say our selected ion channels are named: SLC1 & SLC2\n",
    "# SLC1 needs the CellML template M1 and parameterset P1_0\n",
    "# SLC2 needs the CellML template M2 and parameterset P2_0\n",
    "# The output of this section is a dictionary ('inUse') which contains\n",
    "# the relevent connectivity matrix and parameters\n",
    "# for each selected ion channel/transporter\n",
    "\n",
    "channelSelected = ['SLC1', 'SLC2']\n",
    "inUse={}\n",
    "for selected in channelSelected:\n",
    "    for key in templateGroups.keys():\n",
    "        for transporterName,i in zip(templateGroups[key],range(len(templateGroups[key]))):\n",
    "            if selected == transporterName:\n",
    "                inUse[selected]=[]\n",
    "                inUse[transporterName].append(key)\n",
    "            \n",
    "\n",
    "print('inUse ==>' ,inUse)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the annotations\n",
    "\n",
    "Retreiving the annotations from the CellML parameter files. \n",
    "The biological structures might have the same bond grpah representation (template) but each structure has its own unique parameter values.\n",
    "We have stored the parameters for each structure in a CellML file. The parameters are annotated and the file name has the same name as the biological structure. For example, here the structures **SLC1 & SLC2** are selected from the flatmap and the parameters are retrieved from **SLC1.cellml & SLC2.cellml**. Using the following function (**getAnnotations**), we extract the annotations as RDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Retreiving the annotations from the CellML parameter files\n",
    "def getAnnotations(add):\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "    root = etree.parse(add, parser).getroot()\n",
    "    rdfGraph = rdflib.Graph()\n",
    "    for rdfElement in root.iter():\n",
    "        if rdfElement.tag.endswith('RDF'):\n",
    "            try:\n",
    "                rdfGraph.parse(data = etree.tostring(rdfElement), format=\"application/rdf+xml\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    def getLeaves(sbj, graph):\n",
    "        triples = list(graph.triples((sbj,None,None)))\n",
    "        leaves = []\n",
    "        if len(triples)>0:\n",
    "            for s, p, o in triples:\n",
    "                result =  getLeaves(o,graph)\n",
    "                leaves += result\n",
    "            return list(set(leaves))\n",
    "        else:\n",
    "            return [sbj]\n",
    "        \n",
    "    # Opens the CellML file and returns the list of variables names\n",
    "    f = open(add,'r')\n",
    "    text = f.read()\n",
    "    root = ET.fromstring(text)\n",
    "\n",
    "    rdfs = root.findall('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF')\n",
    "\n",
    "    List1=[]\n",
    "    for child in rdfs:\n",
    "        for grand in child:\n",
    "            List1.append(grand.attrib.get('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}about'))\n",
    "    \n",
    "    List = list(dict.fromkeys(List1))\n",
    "    if '#metaid0' in List:\n",
    "        List.remove('#metaid0')\n",
    "        \n",
    "        \n",
    "    triplesList={}\n",
    "    for i in range(len(List)):\n",
    "        sbj = rdflib.URIRef(List[i])\n",
    "        triplesList[i]=getLeaves(sbj, rdfGraph)\n",
    "\n",
    "\n",
    "    rdfs=[]\n",
    "    \n",
    "    for item in triplesList:\n",
    "        d = []\n",
    "        for k in range(len(triplesList[item])):\n",
    "            if 'opb' in triplesList[item][k] or 'chebi' in triplesList[item][k] or 'fma' in triplesList[item][k] or 'go' in triplesList[item][k]: \n",
    "                lSplit= triplesList[item][k].split('/')\n",
    "                d.append(lSplit[-1])\n",
    "            else: # free-style descriptions!\n",
    "                d.append(str(triplesList[item][k]))\n",
    "    \n",
    "        rdfs.append(d)\n",
    "\n",
    "    for child in root:\n",
    "        if child.tag == '{http://www.cellml.org/cellml/1.1#}'+'component':\n",
    "            modelComponentName = child.attrib.get('name')\n",
    "    \n",
    "    \n",
    "    listP = []\n",
    "    for item in List:\n",
    "        for x in item.split('.'):\n",
    "            if '#'+modelComponentName == x:\n",
    "                itemP = item.replace(x+'.', '')\n",
    "                listP.append(itemP)\n",
    "                \n",
    "\n",
    "            \n",
    "    return [listP,rdfs,root]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the values\n",
    "\n",
    "The function **valExtraction** retreives the initial values from the CellML parameter files (here, **SLC1.cellml & SLC2.cellml**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "## Extracting values from the Parameterset files (P files)\n",
    "\n",
    "def valExtraction(root,List): \n",
    "    \n",
    "    init=[]; variables=[]; els=[]\n",
    "    \n",
    "    for child in root:\n",
    "        if child.tag == '{http://www.cellml.org/cellml/1.1#}'+'component':\n",
    "            modelComponentName = child.attrib.get('name')\n",
    "            \n",
    "    components = root.findall('{http://www.cellml.org/cellml/1.1#}component')\n",
    "    \n",
    "    for comp in components:\n",
    "        variables.append(comp.findall('{http://www.cellml.org/cellml/1.1#}variable'))\n",
    "        \n",
    "    for element in List:  \n",
    "        for var in variables:\n",
    "            for v in var:   \n",
    "                if modelComponentName+'.'+element == v.attrib['{http://www.cellml.org/metadata/1.0#}id']:\n",
    "                    if 'initial_value' in v.attrib: # if any initial value exists take it\n",
    "                        init.append(v.attrib['initial_value'])    \n",
    "                    else:\n",
    "                        init.append(None)\n",
    "    return init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An all-in-one dictionary\n",
    "\n",
    "For the ease of access, a dictionary (**parametersData**) is defined in which the keys represent the structures' names and the values represent the variable name, RDF, and initial value for each parameter. The structure of the dictionary is as follows:\n",
    "\n",
    "```parametersData[SLC1] = [[variable1 , RDF1 , initial value1], [variable2 , RDF2 , initial value2],...]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "annotations={}\n",
    "for transporterName in inUse:\n",
    "    addressP = '/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction/oneReactionModules/{0}.cellml'.format(transporterName)\n",
    "    [List,rdfs,root] = getAnnotations(addressP)\n",
    "    initialVals = valExtraction(root,List)\n",
    "    annotations[transporterName] = []\n",
    "    annotations[transporterName] = [List,rdfs,initialVals]\n",
    "    \n",
    "parametersData = {}\n",
    "for key in annotations:\n",
    "    parametersData[key] = []\n",
    "    for j in range(len(annotations[key][0])):\n",
    "        parametersData[key].append([annotations[key][0][j],annotations[key][1][j],annotations[key][2][j]])\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for linking points\n",
    "\n",
    "To find out how the selected biological structures must be connected to each other, we need to find their mutual entities/components. For instance, in the surrent example of **SLC1 & SLC2**, the concentration of **B** is common between the two structure. This is understood by the following function (**checkMutual**). This function searches for identical RDFs among the selected models in the **parametersData** dictionary. If the common entities (here, B) do not have the same initial values, the function asks the user to choose between the values or insert a new value. The dictionary **parametersData** will then be updated by the new inserted values.\n",
    "\n",
    "You'll see that the initial concentration of B (with the RDF: ```['OPB_00340', 'B']```) and its species constant (with the RDF: ```['OPB_00079', 'B']```) have different values in SLC1 & SLC2. In both cases we decided to insert new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def checkMutual(parametersData):\n",
    "\n",
    "    repeat = []\n",
    "    mutualVars={}\n",
    "    commonAnnotsDiffVals = {}; CommonAmountsAA = {}; CommonAmountsBB = {};\n",
    "    for k1 in range(len(list(parametersData))):\n",
    "        for k2 in range(len(list(parametersData))):\n",
    "            if list(parametersData)[k1] != list(parametersData)[k2] and (list(parametersData)[k1],list(parametersData)[k2]) not in repeat and (list(parametersData)[k2],list(parametersData)[k1]) not in repeat:    \n",
    "                if (list(parametersData.keys())[k1],list(parametersData.keys())[k2]) not in mutualVars:\n",
    "                    mutualVars[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])]=[]\n",
    "\n",
    "                for i1 in range(len(list(parametersData.values())[k1])):\n",
    "                    for i2 in range(len(list(parametersData.values())[k2])):\n",
    "                        if all(elem in list(parametersData.values())[k1][i1][1] for elem in list(parametersData.values())[k2][i2][1]):\n",
    "                            repeat.append((list(parametersData)[k1],list(parametersData)[k2]))\n",
    "\n",
    "                            mutualVars[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k1][i1][0])\n",
    "                            mutualVars[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k1][i1][1])\n",
    "\n",
    "                            if list(parametersData.values())[k1][i1][2] != list(parametersData.values())[k2][i2][2]:\n",
    "\n",
    "                                if (list(parametersData.keys())[k1],list(parametersData.keys())[k2]) not in commonAnnotsDiffVals:\n",
    "                                    commonAnnotsDiffVals[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])]=[]\n",
    "                                    CommonAmountsAA[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])] = []\n",
    "                                    CommonAmountsBB[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])] = []\n",
    "\n",
    "                                commonAnnotsDiffVals[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k1][i1][1])\n",
    "                                CommonAmountsAA[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k1][i1][2])\n",
    "                                CommonAmountsBB[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k2][i2][2])\n",
    "\n",
    "    # Getting the preferred value from the user for the recognised same variables with different values\n",
    "    for i in range(len(list(commonAnnotsDiffVals.keys()))):\n",
    "        for j in range(len(list(commonAnnotsDiffVals.values())[i])):\n",
    "            print('Different values found for: ')\n",
    "            print('\\n')\n",
    "            print(list(commonAnnotsDiffVals.values())[i][j] ,list(commonAnnotsDiffVals.keys())[i],':',list(CommonAmountsAA.values())[i][j],  'and' , list(CommonAmountsBB.values())[i][j])   \n",
    "            list(CommonAmountsAA.values())[i][j]=copy.deepcopy(input('Enter the preferred value:'))\n",
    "\n",
    "\n",
    "    # Copying the changed values to the list of initial amounts of the model    \n",
    "    for mutualTransporters in commonAnnotsDiffVals: # (x,y)\n",
    "        for val1,i in zip(commonAnnotsDiffVals[mutualTransporters],range(len(commonAnnotsDiffVals[mutualTransporters]))):\n",
    "            for transporterName in parametersData: \n",
    "                for val2 in parametersData[transporterName]:\n",
    "                    if transporterName == mutualTransporters[0] and all(elem in val1 for elem in val2[1]):\n",
    "                        val2[2] = copy.deepcopy(CommonAmountsAA[mutualTransporters][i])\n",
    "                    if transporterName == mutualTransporters[1] and all(elem in val1 for elem in val2[1]):\n",
    "                        val2[2] = copy.deepcopy(CommonAmountsAA[mutualTransporters][i])\n",
    "\n",
    "    return [parametersData,mutualVars]               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different values found for: \n",
      "\n",
      "\n",
      "['OPB_00079', 'B'] ('SLC1', 'SLC2') : 5 and 10\n",
      "Enter the preferred value:0.2\n",
      "Different values found for: \n",
      "\n",
      "\n",
      "['OPB_00340', 'B'] ('SLC1', 'SLC2') : 0.1 and 7\n",
      "Enter the preferred value:2\n"
     ]
    }
   ],
   "source": [
    "[parametersData,mutualVars] = checkMutual(parametersData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference annotations\n",
    "\n",
    "As mentioned before, multiple biological structures can be modelled using one single template. The templates have components with random names. We need to have a reference to see which annotations (RDFs) can be assigned to these components. For example, in the 'M1' template, the component 'A' can be either ```['A', 'OPB_00340']``` or ```['F', 'OPB_00340']```. This reference is defined in **referenceAnnotations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "referenceAnnotations = {'M1': [{'A':[['A', 'OPB_00340'],['F', 'OPB_00340']]},\n",
    "                               {'B':[['B', 'OPB_00340']]},\n",
    "                               {'D':[['D', 'OPB_00340']]},\n",
    "                               {'K_A':[['OPB_00079', 'A']]},\n",
    "                               {'K_B':[['OPB_00079', 'B']]},                              \n",
    "                               {'K_D':[['OPB_00079', 'D']]},\n",
    "                               {'kappa_Re1':[['OPB_01296', 'SLC1_Re1']]}],\n",
    "                       'M2': [{'C':[['C', 'OPB_00340']]},\n",
    "                              {'B':[['OPB_00340', 'B']]},\n",
    "                              {'K_C':[['C', 'OPB_00079']]},\n",
    "                              {'K_B':[['B', 'OPB_00079']]},\n",
    "                              {'kappa_Re1':[['OPB_01296', 'SLC2_Re1']]}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the templates using dictionaries\n",
    "\n",
    "3 primary dictionaries work as templates for bond graph models of biological structures:\n",
    "\n",
    "- **Reactions:** for each template (M1, M2, ...) the reactions are defined.\n",
    "\n",
    "- **reaction_reactants_templates:** the reactants along with their stoichiometries are defined for each reaction inside the templates.\n",
    "\n",
    "- **reaction_products_templates:** the products along with their stoichiometries are defined for each reaction inside the templates.\n",
    "\n",
    "It's worth mentioning that the concentrations' names used in the templates (the above 3 dictionaries) are the same arbitrary names used in **referenceAnnotations**. The specified models will be created in the next stage by applying the extracted annotations from the selected CellML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reactions={'M1': ['Re1'],\n",
    "           'M2': ['Re1']}\n",
    "reaction_reactants_templates={'M1': [{'Re1':[(2,'A')]}],\n",
    "                              'M2': [{'Re1':[(1,'B')]}]}\n",
    "\n",
    "reaction_products_templates={'M1': [{'Re1':[(1,'B'),(1,'D')]}],\n",
    "                             'M2': [{'Re1':[(1,'C')]}]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure specific model creation\n",
    "\n",
    "Combining the data from **parametersData** and the templates' information (**reaction_reactants_templates** & **reaction_products_templates**). This adds the RDFs to the templates. Two dictionaries are generated:\n",
    "\n",
    "- reaction_reactants\n",
    "\n",
    "- reaction_products\n",
    "\n",
    "Each of these two dictionaries include the initial values and the RDF for the reactants/products for each reaction inside the biological structures. For instance, **reaction_reactants** reads:\n",
    "\n",
    "```{'SLC1_Re1': [(2, ['A', 'OPB_00340', 'SLC1'])], 'SLC2_Re1': [(1, ['OPB_00340', 'B', 'SLC2'])]}```\n",
    " \n",
    "This means that the reaction ```Re1``` in the structure ```SLC1``` has a reactant with the stoichiometry of ```2``` and RDF of ```['A', 'OPB_00340', 'SLC1']```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "reaction_reactants={}\n",
    "reaction_products={}\n",
    "for transporterName in parametersData:  \n",
    "    for entity in parametersData[transporterName]:\n",
    "        for reaction in Reactions[inUse[transporterName][0]]:\n",
    "            if transporterName+'_'+reaction in entity[1]:\n",
    "                reaction_reactants[transporterName+'_'+reaction]=[]\n",
    "                reaction_products[transporterName+'_'+reaction]=[]\n",
    "                for stoi in reaction_reactants_templates[inUse[transporterName][0]]:\n",
    "                    for key,values in stoi.items():\n",
    "                        if key == reaction:\n",
    "                            for value in values: # (value[0],value[1])=(1,Ai)\n",
    "                                for reference in referenceAnnotations[inUse[transporterName][0]]:\n",
    "                                    for ID in reference:\n",
    "                                        for annot in reference[ID]:\n",
    "                                            if ID == value[1] and all(element in annot for element in annot): \n",
    "                                                X=copy.deepcopy(annot)\n",
    "                                                X.append(transporterName)\n",
    "                                                reaction_reactants[transporterName+'_'+reaction].append((value[0],X))\n",
    "                for stoi in reaction_products_templates[inUse[transporterName][0]]:\n",
    "                    for key,values in stoi.items():\n",
    "                        if key == reaction:\n",
    "                            for value in values: # (value[0],value[1])=(1,Ai)\n",
    "                                for reference in referenceAnnotations[inUse[transporterName][0]]:\n",
    "                                    for ID in reference:\n",
    "                                        for annot in reference[ID]:\n",
    "                                            if ID == value[1] and all(element in annot for element in annot): \n",
    "                                                X=copy.deepcopy(annot)\n",
    "                                                X.append(transporterName)\n",
    "                                                reaction_products[transporterName+'_'+reaction].append((value[0],X))                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of fluxes and list of species\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = []\n",
    "for flux in reaction_reactants:\n",
    "    V.append(flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Species = []\n",
    "for transporterName in parametersData:\n",
    "    for entity in parametersData[transporterName]:\n",
    "        if 'OPB_00340' in entity[1]:\n",
    "            X = copy.deepcopy(entity[1])\n",
    "            X.append(transporterName)\n",
    "            Species.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# might just be needed for parameter estimation\n",
    "\n",
    "# speciesAndRatesList = Species + V\n",
    "\n",
    "\n",
    "# reactionEquations = np.zeros((len(V),len(speciesAndRatesList))) \n",
    "\n",
    "    \n",
    "# for r,reaction in zip(range(len(V)),V):\n",
    "#     for s in range(len(speciesAndRatesList)):\n",
    "#         if speciesAndRatesList[s] == V[r]:\n",
    "#             reactionEquations[r][s] = 1\n",
    "            \n",
    "# # substrates & products (MA)\n",
    "# for reaction in reaction_reactants:  \n",
    "#     for r,rate in zip(range(len(V)),V):\n",
    "#         if reaction in rate:\n",
    "#             for stoi,ids in reaction_reactants[reaction]:\n",
    "#                 for s in range(len(speciesAndRatesList)):\n",
    "#                     if all(el in speciesAndRatesList[s] for el in ids):\n",
    "#                         reactionEquations[r][s] = -stoi\n",
    "#             for stoi,ids in reaction_products[reaction]:\n",
    "#                 for s in range(len(speciesAndRatesList)):\n",
    "#                     if all(el in speciesAndRatesList[s] for el in ids):\n",
    "#                         reactionEquations[r][s] = stoi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     1,
     13
    ]
   },
   "outputs": [],
   "source": [
    "M=np.zeros((len(Species),len(V)))\n",
    "for s in range(len(Species)):\n",
    "    for key,i in zip(reaction_products,range(len(reaction_products))):\n",
    "        for stoi,val  in reaction_products[key]:\n",
    "            if all(el in val for el in Species[s]):\n",
    "                M[s][i] = stoi\n",
    "    for key,i in zip(reaction_reactants,range(len(reaction_reactants))):\n",
    "        for stoi,val in reaction_reactants[key]:\n",
    "            if all(el in val for el in Species[s]):\n",
    "                M[s][i] = -stoi\n",
    "\n",
    "\n",
    "speciesNoDuplicate = []\n",
    "for s in Species:\n",
    "    for transporterName in inUse:\n",
    "        if transporterName in s:\n",
    "            ss = copy.deepcopy(s)\n",
    "            ss.remove(transporterName)\n",
    "            if ss not in speciesNoDuplicate:\n",
    "                speciesNoDuplicate.append(ss)\n",
    "        \n",
    "\n",
    "N=np.zeros((len(speciesNoDuplicate),len(V)))\n",
    "for transporterName in inUse:\n",
    "    for v,i in zip(V,range(len(V))):\n",
    "        if transporterName in v:\n",
    "            for s1 in range(len(speciesNoDuplicate)):\n",
    "                for s2 in range(len(Species)):\n",
    "                    if transporterName in Species[s2]:\n",
    "                        if all(el in Species[s2] for el in speciesNoDuplicate[s1]):\n",
    "                            N[s1][i] = M[s2][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "speciesConstants=[]\n",
    "for species in speciesNoDuplicate:\n",
    "    X = copy.deepcopy(species)\n",
    "    X.remove('OPB_00340')\n",
    "    for transporterName in parametersData:\n",
    "        for entity in parametersData[transporterName]:\n",
    "            if all(el in entity[1] for el in ['OPB_00079']+X) and entity[1] not in speciesConstants:\n",
    "                \n",
    "                speciesConstants.append(entity[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to write into a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what name have you chosen for the unit of concentration?\n",
      "fmol\n",
      "what name have you chosen for the unit of species constant (K)?\n",
      "per_fmol\n",
      "what name have you chosen for the unit of flux?\n",
      "fmol_per_sec\n"
     ]
    }
   ],
   "source": [
    "print('what name have you chosen for the unit of concentration?')\n",
    "concentrationUnit = input()\n",
    "print('what name have you chosen for the unit of species constant (K)?')\n",
    "speciesConstantUnit = input()\n",
    "print('what name have you chosen for the unit of flux?')\n",
    "fluxUnit = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     25,
     44,
     63,
     72,
     85,
     114
    ]
   },
   "outputs": [],
   "source": [
    "# Create a text file (TEXT)\n",
    "\n",
    "unitsImport = ['def model composed_model as',\n",
    "               '\\tdef import using \"units_BG.cellml\" for',\n",
    "                '\\t\\tunit {0} using unit {0};'.format(concentrationUnit),\n",
    "               '\\t\\tunit {0} using unit {0};'.format(speciesConstantUnit),\n",
    "               '\\t\\tunit {0} using unit {0};'.format(fluxUnit),\n",
    "                '\\tenddef;',\n",
    "              '\\tdef comp main as']\n",
    "\n",
    "with open('GFG.txt', 'w') as fp:\n",
    "    pass    \n",
    "with open('GFG.txt', 'a') as file:\n",
    "    for line in unitsImport:\n",
    "        file.write(line+'\\n')\n",
    "\n",
    "        \n",
    "with open('GFG.txt', 'a') as file:\n",
    "    file.write('\\t\\tvar t: second {init: 0};'+'\\n')\n",
    "    \n",
    "cellmlRef=[]        \n",
    "\n",
    "q = ['q_{0}'.format(x) for x in range(1000)]\n",
    "k=0\n",
    "checkDup=[]\n",
    "for species,i in zip(speciesNoDuplicate,range(len(speciesNoDuplicate))):\n",
    "        for transporterName,annotation in parametersData.items():\n",
    "            for value in annotation:\n",
    "                if all(el in value[1] for el in species):\n",
    "                    flag=0; \n",
    "                    for j in range(len(checkDup)):\n",
    "                        if all(x in checkDup[j] for x in value[1]):\n",
    "                            flag=1\n",
    "                                \n",
    "                    if flag==0:\n",
    "                        checkDup.append(value[1])\n",
    "                        cellmlRef.append((value[1],q[k]))\n",
    "                        with open('GFG.txt', 'a') as file:\n",
    "                            file.write('\\t\\tvar ' +q[k]+': '+'fmol '+'{'+'init: '+value[2]+'}'+';'+'\\n')\n",
    "                            k+=1\n",
    "                        \n",
    "K = ['K_{0}'.format(x) for x in range(1000)]\n",
    "k=0\n",
    "checkDup=[]\n",
    "for constant,i in zip(speciesConstants,range(len(speciesConstants))):\n",
    "    for transporterName,annotation in parametersData.items():\n",
    "        for value in annotation:\n",
    "            if all(el in value[1] for el in constant):\n",
    "                flag=0; \n",
    "                for j in range(len(checkDup)):\n",
    "                    if all(x in checkDup[j] for x in value[1]):\n",
    "                        flag=1\n",
    "\n",
    "                if flag==0:\n",
    "                    checkDup.append(value[1])\n",
    "                    cellmlRef.append((value[1],K[k]))\n",
    "                    with open('GFG.txt', 'a') as file:\n",
    "                        file.write('\\t\\tvar '+K[k]+': '+'per_fmol '+'{'+'init: '+value[2]+'}'+';'+'\\n')\n",
    "                        k+=1     \n",
    "\n",
    "                        \n",
    "v = ['v_{0}'.format(x) for x in range(1000)]\n",
    "k=0\n",
    "for flux in reaction_reactants:\n",
    "    cellmlRef.append((flux,v[k]))\n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write('\\t\\tvar '+v[k]+': '+'fmol_per_sec '+';'+'\\n')\n",
    "        k+=1\n",
    "\n",
    "        \n",
    "kappa = ['kappa_{0}'.format(x) for x in range(1000)]\n",
    "k=0\n",
    "for flux,i in zip(V,range(len(V))): \n",
    "    for transporterName,annotation in parametersData.items():\n",
    "        for value in annotation:\n",
    "            if flux in value[1]:\n",
    "                cellmlRef.append((value[1],kappa[k]))\n",
    "                with open('GFG.txt', 'a') as file:\n",
    "                    file.write('\\t\\tvar '+ kappa[k]+': '+'fmol_per_sec '+'{'+'init: '+value[2]+'}'+';'+'\\n')\n",
    "                    k+=1\n",
    "\n",
    "# Generating the ODEs       \n",
    "with open('GFG.txt', 'a') as file:\n",
    "    file.write('\\n')\n",
    "    \n",
    "for i in range(np.shape(N)[0]):\n",
    "    for annotation,ID in cellmlRef:\n",
    "        if all(ele in speciesNoDuplicate[i] for ele in annotation):\n",
    "            with open('GFG.txt', 'a') as file:\n",
    "                file.write('\\t\\tode('+ID+',t)=')\n",
    "            for j in range(np.shape(N)[1]):  \n",
    "\n",
    "                if N[i][j] != 0:\n",
    "\n",
    "                    if N[i][j] > 0:\n",
    "                        for annotation2,ID2 in cellmlRef:\n",
    "                            if V[j] == annotation2:\n",
    "                                with open('GFG.txt', 'a') as file:\n",
    "                                    file.write('+'+str(N[i][j])+'{dimensionless}*'+ID2)\n",
    "\n",
    "                if N[i][j] < 0:\n",
    "                    for annotation2,ID2 in cellmlRef:\n",
    "                        if V[j] == annotation2:\n",
    "                            with open('GFG.txt', 'a') as file:\n",
    "                                file.write(str(N[i][j])+'{dimensionless}*'+ID2)\n",
    "                                \n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write(';\\n')\n",
    "\n",
    "        \n",
    "# Generating the reaction rates\n",
    "with open('GFG.txt', 'a') as file:\n",
    "    file.write('\\n')\n",
    "\n",
    "for flux in V:\n",
    "    for annotation1,ID1 in cellmlRef:\n",
    "        if flux == annotation1:\n",
    "            with open('GFG.txt', 'a') as file:\n",
    "                file.write('\\t\\t '+ ID1+'= ') \n",
    "            for annotation2,ID2 in cellmlRef:\n",
    "                if all(el in [flux]+['OPB_01296'] for el in annotation2):\n",
    "                    with open('GFG.txt', 'a') as file:\n",
    "                        file.write(ID2+'*(') \n",
    "    length = 0                    \n",
    "    for stoi,reactant in reaction_reactants[flux]:\n",
    "        length+=1\n",
    "        for annotation,ID in cellmlRef:\n",
    "            if all(el in reactant for el in annotation):\n",
    "                Q = copy.deepcopy(annotation)\n",
    "                Q.remove('OPB_00340')\n",
    "                for annotation2,ID2 in cellmlRef:\n",
    "                    if all(el in Q+['OPB_00079'] for el in annotation2):\n",
    "                        with open('GFG.txt', 'a') as file:\n",
    "                            file.write('pow('+ID+'*'+ID2+','+str(stoi)+'{dimensionless}'+')') \n",
    "        \n",
    "        if length < len(reaction_reactants[flux]):\n",
    "            with open('GFG.txt', 'a') as file:\n",
    "                file.write(' * ')\n",
    "            \n",
    "            \n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write(' - ')\n",
    "    \n",
    "    length = 0 \n",
    "    for stoi,product in reaction_products[flux]:\n",
    "        length+=1\n",
    "        for annotation,ID in cellmlRef:\n",
    "            if all(el in product for el in annotation):\n",
    "                Q = copy.deepcopy(annotation)\n",
    "                Q.remove('OPB_00340')\n",
    "                for annotation2,ID2 in cellmlRef:\n",
    "                    if all(el in Q+['OPB_00079'] for el in annotation2):\n",
    "                        with open('GFG.txt', 'a') as file:\n",
    "                            file.write('pow('+ID+'*'+ID2+','+str(stoi)+'{dimensionless}'+')') \n",
    "       \n",
    "        if length < len(reaction_products[flux]):\n",
    "            with open('GFG.txt', 'a') as file:\n",
    "                file.write(' * ')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write(');\\n')\n",
    "                                \n",
    "                    \n",
    "    \n",
    "    \n",
    "        \n",
    "with open('GFG.txt', 'a') as file:\n",
    "    file.write('\\tenddef;'+'\\n'+'enddef;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     2,
     3
    ]
   },
   "outputs": [],
   "source": [
    "meaning = {}\n",
    "\n",
    "def rdfMeaning(meaning,var,el):\n",
    "    if 'OPB' in el:\n",
    "        numCell=re.findall(r'\\d+', el)\n",
    "        for j in range(len(opbID)):\n",
    "            numID=re.findall(r'\\d+', opbID[j])\n",
    "            if numCell == numID:\n",
    "                meaning[var].append(opbLabel[j])\n",
    "    if 'CHEBI' in el:\n",
    "        numCell=re.findall(r'\\d+', el)\n",
    "        for j in range(len(chebiID)):\n",
    "            numID=re.findall(r'\\d+', chebiID[j])\n",
    "            if numCell == numID:\n",
    "                meaning[var].append(chebiLabel[j])\n",
    "    if 'GO' in el:\n",
    "        numCell=re.findall(r'\\d+', el)\n",
    "        for j in range(len(goID)):\n",
    "            numID=re.findall(r'\\d+', goID[j])\n",
    "            if numCell == numID:\n",
    "                meaning[var].append(goLabel[j])\n",
    "    if 'fma' in el:\n",
    "        numCell=re.findall(r'\\d+', el)\n",
    "        for j in range(len(fmaID)):\n",
    "            numID=re.findall(r'\\d+', fmaID[j])\n",
    "            if numCell == numID:\n",
    "                meaning[var].append(fmaLabel[j])\n",
    "    if ('OPB' not in el) and ('CHEBI' not in el) and('GO' not in el) and ('fma' not in el):\n",
    "        meaning[var].append(el)\n",
    "    return meaning\n",
    "\n",
    "for rdfs,var in cellmlRef: \n",
    "    if type(rdfs)==list:\n",
    "        meaning[var]=[]\n",
    "        for el in rdfs:\n",
    "            meaning = rdfMeaning(meaning,var,el)\n",
    "            \n",
    "    else:\n",
    "        meaning[var]=[]\n",
    "        meaning = rdfMeaning(meaning,var,rdfs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating an .xlsx file to map the CellML variables to their meanings\n",
    "\n",
    "workbook = xlsxwriter.Workbook('variables guide2.xlsx')\n",
    "worksheet1 = workbook.add_worksheet()\n",
    "# Add a format. Light red fill with dark red text.\n",
    "format1 = workbook.add_format({'bold':     True,\n",
    "                               'border':   3,\n",
    "                               'bg_color': '#FFC7CE',\n",
    "                               'font_color': '#9C0006'})\n",
    "# Add a format. Green fill with dark green text.\n",
    "format2 = workbook.add_format({'bold':     True,\n",
    "                               'border':   3,\n",
    "                               'bg_color': '#C6EFCE',\n",
    "                               'font_color': '#006100'})\n",
    "\n",
    "header = (\"Variable\", \"Annotation\", \"Meaning\")\n",
    "worksheet1.write_row('A1',header,format1)\n",
    "worksheet1.set_column(1, 35, 35)\n",
    "\n",
    "\n",
    "row=0\n",
    "for rdf,var in cellmlRef:\n",
    "    worksheet1.write_row(row+1, 0, [var],format2)\n",
    "    worksheet1.write_row(row+1, 1, [str(rdf)])\n",
    "    worksheet1.write_row(row+1, 2, [str(meaning[var])])\n",
    "    row+=1\n",
    "    \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a JSON file including:\n",
    "### - Variable names\n",
    "### - Variable values\n",
    "### - Variable RDFs\n",
    "### - RDF meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Data to be written\n",
    "dictionary = dict()\n",
    "for i,item1 in enumerate(cellmlRef):\n",
    "    dictionary[item1[1]] = {}\n",
    "    for key,values in parametersData.items():  \n",
    "        for j,item2 in enumerate(values):\n",
    "            if all(el in item1[0] for el in item2[1]):\n",
    "                dictionary[item1[1]]['value'] = item2[2]\n",
    "                dictionary[item1[1]]['rdf'] = str(item2[1])\n",
    "                dictionary[item1[1]]['meaning'] = str(meaning[item1[1]])\n",
    "        \n",
    "# Serializing json\n",
    "json_object = json.dumps(dictionary, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Kernel will be changed into .NET (PowerShell) to run this cell\n",
    "## This cell generates a CellML file from the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.session.restart({kernel_name: '.net-powershell'})\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.restart({kernel_name: '.net-powershell'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\r\n",
       "<div>\r\n",
       "    <div id='dotnet-interactive-this-cell-19188.Microsoft.DotNet.Interactive.Http.HttpPort' style='display: none'>\r\n",
       "        The below script needs to be able to find the current output cell; this is an easy method to get it.\r\n",
       "    </div>\r\n",
       "    <script type='text/javascript'>\r\n",
       "async function probeAddresses(probingAddresses) {\r\n",
       "    function timeout(ms, promise) {\r\n",
       "        return new Promise(function (resolve, reject) {\r\n",
       "            setTimeout(function () {\r\n",
       "                reject(new Error('timeout'))\r\n",
       "            }, ms)\r\n",
       "            promise.then(resolve, reject)\r\n",
       "        })\r\n",
       "    }\r\n",
       "\r\n",
       "    if (Array.isArray(probingAddresses)) {\r\n",
       "        for (let i = 0; i < probingAddresses.length; i++) {\r\n",
       "\r\n",
       "            let rootUrl = probingAddresses[i];\r\n",
       "\r\n",
       "            if (!rootUrl.endsWith('/')) {\r\n",
       "                rootUrl = `${rootUrl}/`;\r\n",
       "            }\r\n",
       "\r\n",
       "            try {\r\n",
       "                let response = await timeout(1000, fetch(`${rootUrl}discovery`, {\r\n",
       "                    method: 'POST',\r\n",
       "                    cache: 'no-cache',\r\n",
       "                    mode: 'cors',\r\n",
       "                    timeout: 1000,\r\n",
       "                    headers: {\r\n",
       "                        'Content-Type': 'text/plain'\r\n",
       "                    },\r\n",
       "                    body: probingAddresses[i]\r\n",
       "                }));\r\n",
       "\r\n",
       "                if (response.status == 200) {\r\n",
       "                    return rootUrl;\r\n",
       "                }\r\n",
       "            }\r\n",
       "            catch (e) { }\r\n",
       "        }\r\n",
       "    }\r\n",
       "}\r\n",
       "\r\n",
       "function loadDotnetInteractiveApi() {\r\n",
       "    probeAddresses([\"http://130.216.209.19:1000/\", \"http://127.0.0.1:1000/\"])\r\n",
       "        .then((root) => {\r\n",
       "        // use probing to find host url and api resources\r\n",
       "        // load interactive helpers and language services\r\n",
       "        let dotnetInteractiveRequire = require.config({\r\n",
       "        context: '19188.Microsoft.DotNet.Interactive.Http.HttpPort',\r\n",
       "                paths:\r\n",
       "            {\r\n",
       "                'dotnet-interactive': `${root}resources`\r\n",
       "                }\r\n",
       "        }) || require;\r\n",
       "\r\n",
       "            window.dotnetInteractiveRequire = dotnetInteractiveRequire;\r\n",
       "\r\n",
       "            window.configureRequireFromExtension = function(extensionName, extensionCacheBuster) {\r\n",
       "                let paths = {};\r\n",
       "                paths[extensionName] = `${root}extensions/${extensionName}/resources/`;\r\n",
       "                \r\n",
       "                let internalRequire = require.config({\r\n",
       "                    context: extensionCacheBuster,\r\n",
       "                    paths: paths,\r\n",
       "                    urlArgs: `cacheBuster=${extensionCacheBuster}`\r\n",
       "                    }) || require;\r\n",
       "\r\n",
       "                return internalRequire\r\n",
       "            };\r\n",
       "        \r\n",
       "            dotnetInteractiveRequire([\r\n",
       "                    'dotnet-interactive/dotnet-interactive'\r\n",
       "                ],\r\n",
       "                function (dotnet) {\r\n",
       "                    dotnet.init(window);\r\n",
       "                },\r\n",
       "                function (error) {\r\n",
       "                    console.log(error);\r\n",
       "                }\r\n",
       "            );\r\n",
       "        })\r\n",
       "        .catch(error => {console.log(error);});\r\n",
       "    }\r\n",
       "\r\n",
       "// ensure `require` is available globally\r\n",
       "if ((typeof(require) !==  typeof(Function)) || (typeof(require.config) !== typeof(Function))) {\r\n",
       "    let require_script = document.createElement('script');\r\n",
       "    require_script.setAttribute('src', 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js');\r\n",
       "    require_script.setAttribute('type', 'text/javascript');\r\n",
       "    \r\n",
       "    \r\n",
       "    require_script.onload = function() {\r\n",
       "        loadDotnetInteractiveApi();\r\n",
       "    };\r\n",
       "\r\n",
       "    document.getElementsByTagName('head')[0].appendChild(require_script);\r\n",
       "}\r\n",
       "else {\r\n",
       "    loadDotnetInteractiveApi();\r\n",
       "}\r\n",
       "\r\n",
       "    </script>\r\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  .net-csharp        C:\\Users\\nsha457\\AppData\\Roaming\\jupyter\\kernels\\.net-csharp\n",
      "  .net-fsharp        C:\\Users\\nsha457\\AppData\\Roaming\\jupyter\\kernels\\.net-fsharp\n",
      "  .net-powershell    C:\\Users\\nsha457\\AppData\\Roaming\\jupyter\\kernels\\.net-powershell\n",
      "  python3            C:\\Users\\nsha457\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3\n"
     ]
    }
   ],
   "source": [
    "jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\r\n",
       "<div>\r\n",
       "    <div id='dotnet-interactive-this-cell-3176.Microsoft.DotNet.Interactive.Http.HttpPort' style='display: none'>\r\n",
       "        The below script needs to be able to find the current output cell; this is an easy method to get it.\r\n",
       "    </div>\r\n",
       "    <script type='text/javascript'>\r\n",
       "async function probeAddresses(probingAddresses) {\r\n",
       "    function timeout(ms, promise) {\r\n",
       "        return new Promise(function (resolve, reject) {\r\n",
       "            setTimeout(function () {\r\n",
       "                reject(new Error('timeout'))\r\n",
       "            }, ms)\r\n",
       "            promise.then(resolve, reject)\r\n",
       "        })\r\n",
       "    }\r\n",
       "\r\n",
       "    if (Array.isArray(probingAddresses)) {\r\n",
       "        for (let i = 0; i < probingAddresses.length; i++) {\r\n",
       "\r\n",
       "            let rootUrl = probingAddresses[i];\r\n",
       "\r\n",
       "            if (!rootUrl.endsWith('/')) {\r\n",
       "                rootUrl = `${rootUrl}/`;\r\n",
       "            }\r\n",
       "\r\n",
       "            try {\r\n",
       "                let response = await timeout(1000, fetch(`${rootUrl}discovery`, {\r\n",
       "                    method: 'POST',\r\n",
       "                    cache: 'no-cache',\r\n",
       "                    mode: 'cors',\r\n",
       "                    timeout: 1000,\r\n",
       "                    headers: {\r\n",
       "                        'Content-Type': 'text/plain'\r\n",
       "                    },\r\n",
       "                    body: probingAddresses[i]\r\n",
       "                }));\r\n",
       "\r\n",
       "                if (response.status == 200) {\r\n",
       "                    return rootUrl;\r\n",
       "                }\r\n",
       "            }\r\n",
       "            catch (e) { }\r\n",
       "        }\r\n",
       "    }\r\n",
       "}\r\n",
       "\r\n",
       "function loadDotnetInteractiveApi() {\r\n",
       "    probeAddresses([\"http://130.216.209.19:1000/\", \"http://127.0.0.1:1000/\"])\r\n",
       "        .then((root) => {\r\n",
       "        // use probing to find host url and api resources\r\n",
       "        // load interactive helpers and language services\r\n",
       "        let dotnetInteractiveRequire = require.config({\r\n",
       "        context: '3176.Microsoft.DotNet.Interactive.Http.HttpPort',\r\n",
       "                paths:\r\n",
       "            {\r\n",
       "                'dotnet-interactive': `${root}resources`\r\n",
       "                }\r\n",
       "        }) || require;\r\n",
       "\r\n",
       "            window.dotnetInteractiveRequire = dotnetInteractiveRequire;\r\n",
       "\r\n",
       "            window.configureRequireFromExtension = function(extensionName, extensionCacheBuster) {\r\n",
       "                let paths = {};\r\n",
       "                paths[extensionName] = `${root}extensions/${extensionName}/resources/`;\r\n",
       "                \r\n",
       "                let internalRequire = require.config({\r\n",
       "                    context: extensionCacheBuster,\r\n",
       "                    paths: paths,\r\n",
       "                    urlArgs: `cacheBuster=${extensionCacheBuster}`\r\n",
       "                    }) || require;\r\n",
       "\r\n",
       "                return internalRequire\r\n",
       "            };\r\n",
       "        \r\n",
       "            dotnetInteractiveRequire([\r\n",
       "                    'dotnet-interactive/dotnet-interactive'\r\n",
       "                ],\r\n",
       "                function (dotnet) {\r\n",
       "                    dotnet.init(window);\r\n",
       "                },\r\n",
       "                function (error) {\r\n",
       "                    console.log(error);\r\n",
       "                }\r\n",
       "            );\r\n",
       "        })\r\n",
       "        .catch(error => {console.log(error);});\r\n",
       "    }\r\n",
       "\r\n",
       "// ensure `require` is available globally\r\n",
       "if ((typeof(require) !==  typeof(Function)) || (typeof(require.config) !== typeof(Function))) {\r\n",
       "    let require_script = document.createElement('script');\r\n",
       "    require_script.setAttribute('src', 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js');\r\n",
       "    require_script.setAttribute('type', 'text/javascript');\r\n",
       "    \r\n",
       "    \r\n",
       "    require_script.onload = function() {\r\n",
       "        loadDotnetInteractiveApi();\r\n",
       "    };\r\n",
       "\r\n",
       "    document.getElementsByTagName('head')[0].appendChild(require_script);\r\n",
       "}\r\n",
       "else {\r\n",
       "    loadDotnetInteractiveApi();\r\n",
       "}\r\n",
       "\r\n",
       "    </script>\r\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "$dpath= 'C:/Program Files/OpenCOR'\n",
    "$txtfiles='GFG'\n",
    "$tpath='C:/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction'\n",
    "$cpath='C:/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction'\n",
    "foreach ($txtfile in $txtfiles){.$dpath/OpenCOR -c CellMLTextView::export $tpath/$txtfile.txt | out-file $cpath/$txtfile.cellml -encoding utf8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
